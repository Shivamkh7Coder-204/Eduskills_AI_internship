{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnCZl/8hOdk4BXk0e6/5Am",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivamkh7Coder-204/Eduskills_AI_internship/blob/main/Shivam_khadde_Eduskills_internship_Ai_sentiment_analysis_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CODE STARTS    ~SHIVAM KHADDE**"
      ],
      "metadata": {
        "id": "MpK-HyFbRPo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sentiment Analysis of Resturant Review.      ~Shivam Khadde \")"
      ],
      "metadata": {
        "id": "dw1fPc598ppr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdxZVrsiwQlD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing essential libraries.\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd #data processing, CSV file I/O (e.g. pd/read_csv)"
      ],
      "metadata": {
        "id": "Qb5WFWBRHDhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Restaurant_Reviews.tsv\",delimiter='\\t',quoting=3) #encoding=\"latin\""
      ],
      "metadata": {
        "id": "w2EMZrgWf8-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape= tuple of array dimensions (row,column)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "gSwchDpuxQyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "22VBhB4CxRds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "FMJ5SA4VxTw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "id": "LoJXMvDGxqZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "id": "Z7df8J9zxsjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[]\n",
        "for i in range(0,1000):\n",
        "  review = re.sub(pattern='[^a-zA-Z]',repl= ' ', string=df['Review'][i])\n",
        "  review = review.lower()\n",
        "  review_words = review.split()\n",
        "  review_words = [word for word in review_words if not word in set(stopwords.words('english'))]\n",
        "  ps = PorterStemmer()\n",
        "  review = [ps.stem(word) for word in review_words]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ],
      "metadata": {
        "id": "qS9XqRJKx3f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[:1500]\n"
      ],
      "metadata": {
        "id": "ZY-RBV2Wyu7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=1500)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "y= df.iloc[:,1].values"
      ],
      "metadata": {
        "id": "D-puMZY5zPyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "ktA9zDbo0cVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape,y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "50nhzoyJ1Ihi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape,y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "qg-Zux2vRyzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify.weka import ClassifierI\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "NI97HcMq1g3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "1Yu8_VH02kSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "score1 = accuracy_score(y_test,y_pred)\n",
        "score2 = precision_score(y_test,y_pred)\n",
        "score3 = recall_score(y_test,y_pred)\n",
        "\n",
        "print(\"-----Scores are-----\")\n",
        "print(\"Accuracy score is {}%\".format(round(score1*100,2)))\n",
        "print(\"Precision score is {}%\".format(round(score2*100,2)))\n",
        "print(\"Recall score is {}%\".format(round(score3*100,2)))"
      ],
      "metadata": {
        "id": "f7KtB1vc3DM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "RI1vbKGgRyzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "plt.figure(figsize = (10,6))\n",
        "sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", xticklabels=['Negative','Positive'], yticklabels=['Negative','Positive'])\n",
        "plt.xlabel('Predicted values')\n",
        "plt.ylabel('Actual values')"
      ],
      "metadata": {
        "id": "PEXqriu25Xn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.io.formats.info import InfoPrinterAbstract\n",
        "best_accuracy = 0.0\n",
        "alpha_val= 0.0\n",
        "for i in np.arange(0.1,1.1,0.1):\n",
        "  temp_classifier = MultinomialNB(alpha=i)\n",
        "  temp_classifier.fit(X_train, y_train)\n",
        "  temp_y_pred = temp_classifier.predict(X_test)\n",
        "  score = accuracy_score(y_test, temp_y_pred)\n",
        "  print(\"Accuracy score for alpha- {} is: {}%\".format(round(i,1), round(score*100,2)))\n",
        "  if score>best_accuracy:\n",
        "    best_accuracy = score\n",
        "    alpha_val = i\n",
        "print(\"------------------------------------------------\")\n",
        "print(\"The best accuracy score is {}% with alpha as {}\".format(round(best_accuracy*100,2), round(alpha_val,1)))"
      ],
      "metadata": {
        "id": "ZoPYf7T76xlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(sample_review):\n",
        "  sample_review = re.sub(pattern='[^a-zA-Z]',repl= ' ', string= sample_review)\n",
        "  sample_review = sample_review.lower()\n",
        "  sample_review_words = sample_review.split()\n",
        "  sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
        "  ps = PorterStemmer()\n",
        "  final_review = [ps.stem(word) for word in sample_review_words]\n",
        "  final_review = ' '.join(final_review)\n",
        "  temp = cv.transform([final_review]).toarray()\n",
        "  return classifier.predict(temp)"
      ],
      "metadata": {
        "id": "F6aiC5FT_1b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting values\n",
        "sample_review = 'the food is really good.'\n",
        "\n",
        "if predict_sentiment(sample_review):\n",
        "  print('This is a POSITIVE review')\n",
        "else:\n",
        "  print('This is a NEGATIVE review!')"
      ],
      "metadata": {
        "id": "oM761JLMBjsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **continue below code lines**"
      ],
      "metadata": {
        "id": "WiM8YsklQnN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting values\n",
        "sample_review = 'Food was pretty bad and the servicce was very slow.'\n",
        "\n",
        "if predict_sentiment(sample_review):\n",
        "  print('This is a POSITIVE review')\n",
        "else:\n",
        "  print('This is a NEGATIVE review!')"
      ],
      "metadata": {
        "id": "9fv3pIK1CbrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **continue below code lines**"
      ],
      "metadata": {
        "id": "Mvj3Jn38Q1x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting values\n",
        "sample_review = 'The food was absolutely ok, from preparation to presentation, very pleasing'\n",
        "\n",
        "if predict_sentiment(sample_review):\n",
        "  print('This is a POSITIVE review')\n",
        "else:\n",
        "  print('This is a NEGATIVE review!')"
      ],
      "metadata": {
        "id": "yOAHim-gCkO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **continue below code lines**"
      ],
      "metadata": {
        "id": "DlpHuV8AQ53i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Load your dataset (replace \"your_dataset.csv\" with the actual file path)\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Restaurant_Reviews.tsv\", delimiter='\\t', quoting=3)\n",
        "\n",
        "# Split the dataset into features (X) and labels (y)\n",
        "X = df['Review'].values\n",
        "y = df['Liked'].values\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(max_features=1500)\n",
        "X_tfidf = tfidf.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Hyperparameter Tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train a Random Forest classifier with the best hyperparameters\n",
        "best_rf_classifier = RandomForestClassifier(random_state=0, **best_params)\n",
        "best_rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = best_rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluation Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "RSrz9FFcB3q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the dataset into features (X) and labels (y)\n",
        "X = df['Review'].values\n",
        "y = df['Liked'].values\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
        "X_tfidf = tfidf.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=300, max_depth=None, min_samples_split=2, random_state=0)\n",
        "\n",
        "# Train the Random Forest classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluation Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "XD92DJ47EadP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into features (X) and labels (y)\n",
        "X = df['Review'].values\n",
        "y = df['Liked'].values\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
        "X_tfidf = tfidf.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=300, max_depth=None, min_samples_split=2, random_state=0)\n",
        "\n",
        "# Train the Random Forest classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on training data\n",
        "y_train_pred = rf_classifier.predict(X_train)\n",
        "\n",
        "# Predictions on testing data\n",
        "y_test_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate training and testing accuracies\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "print(\"Testing Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "KrOZmvDFG4vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting values\n",
        "sample_review = 'The food was absolutely ok, from preparation to presentation, very pleasing'\n",
        "\n",
        "if predict_sentiment(sample_review):\n",
        "  print('This is a POSITIVE review')\n",
        "else:\n",
        "  print('This is a NEGATIVE review!')"
      ],
      "metadata": {
        "id": "ymBDFpNpLvNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting values\n",
        "sample_review = 'pizza tast old super chewi good way.'\n",
        "\n",
        "if predict_sentiment(sample_review):\n",
        "  print('This is a POSITIVE review')\n",
        "else:\n",
        "  print('This is a NEGATIVE review!')"
      ],
      "metadata": {
        "id": "K4i8JFAQNODQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Define and predict the list of sample reviews\n",
        "sample_reviews =['The selection on the menu was great and so wer...',\n",
        "                 'eew locat need complet overhaul',\n",
        "                 'recent wit poor qualiti manag toward guest well',\n",
        "                  'wait wait wait',\n",
        "                  'also came back check us regularli excel servic',\n",
        "                  'server super nice check us mani time',\n",
        "                  'pizza tast old super chewi good way',\n",
        "                 'service good compani better',\n",
        "                 'Food was pretty bad and the service was very slow.',\n",
        "                 'The food was absolutely ok, from preparation to presentation, very pleasing.',\n",
        "                 'the food is really good.']\n",
        "\n",
        "i = 1\n",
        "for sample in sample_reviews:\n",
        "    if predict_sentiment(sample):\n",
        "        print(f'The Review {i} is Positive')\n",
        "    else:\n",
        "        print(f'The Review {i} is Negative')\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "p9uCRxb7Lp8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **New Section**\n",
        "\n",
        "# ** CODE ENDS HERE**\n",
        "\n"
      ],
      "metadata": {
        "id": "BP0LWDPDQ_Cg"
      }
    }
  ]
}